{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from numpy.lib.format import open_memmap\n",
    "import pandas as pd\n",
    "import weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def values_states(desired_state):\n",
    "    \"\"\"\n",
    "    Reads in census data csv. Returns only data for desired state.\n",
    "    \"\"\"\n",
    "    chunk_1 = pd.DataFrame()\n",
    "    reader_a = pd.read_csv('ss16pusa.csv',memory_map=True,chunksize=80000)\n",
    "    for a in reader_a:\n",
    "        chunk_1 = chunk_1.append(a[a['ST']==desired_state])\n",
    "        if max(a['ST'])>desired_state:\n",
    "            break\n",
    "    reader_b = pd.read_csv('ss16pusb.csv',memory_map=True,chunksize=80000)\n",
    "    for a in reader_b:\n",
    "        chunk_1 = chunk_1.append(a[a['ST']==desired_state])\n",
    "        if max(a['ST'])>desired_state:\n",
    "            break\n",
    "    return chunk_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def racially_biased_salaries(desired_state,len_chosen = 10000,check_file = True,filename = 'states.race.income.dat'):\n",
    "    \"\"\"\n",
    "    Returns the weighted median income of white and black respondants after controlling for sex, age, and education.\n",
    "    If check_file, execute only if state isn't already done.\n",
    "    \n",
    "    \"\"\"\n",
    "    if check_file:\n",
    "        states_done = np.loadtxt(filename,skiprows=1)\n",
    "        if len(states_done) == 0:\n",
    "            pass\n",
    "        elif len(states_done.shape)==1:\n",
    "            if states_done[0] == desired_state:\n",
    "                return 'Finished'\n",
    "            else:\n",
    "                pass\n",
    "        elif desired_state in states_done.T[0]:\n",
    "            return 'Finished'\n",
    "    chunk_1 = values_states(desired_state)\n",
    "    some_hs = chunk_1[(chunk_1['SCHL']>11)]\n",
    "    bl_some_hs = chunk_1[(chunk_1['SCHL']>11)&(chunk_1['RAC1P']==2)&(chunk_1['AGEP']>18)&(chunk_1['PINCP']>0)]\n",
    "    wh_some_hs = chunk_1[(chunk_1['SCHL']>11)&(chunk_1['RAC1P']==1)&(chunk_1['AGEP']>18)&(chunk_1['PINCP']>0)]\n",
    "    rand_targets = np.array([np.sum(wh_some_hs['PWGTP'][:i+1]) for i in range(len(wh_some_hs['PWGTP'])+1)])\n",
    "    chosen = []\n",
    "    acts = np.random.randint(0,rand_targets[-1],len_chosen)\n",
    "    for act in acts:\n",
    "        finder = rand_targets<=act\n",
    "        try:\n",
    "            chosen.append(list(finder).index(False))\n",
    "        except IndexError:\n",
    "            chosen.append(-1)\n",
    "    chosen = wh_some_hs.index[chosen]\n",
    "    wh_final = []\n",
    "    bl_final = []\n",
    "    for i in chosen:\n",
    "        matches = bl_some_hs[(bl_some_hs['AGEP'] == wh_some_hs.loc[i]['AGEP'])&(bl_some_hs['SCHL'] == wh_some_hs.loc[i]['SCHL'])]\n",
    "        if len(matches) == 0:\n",
    "            continue\n",
    "        weighted_matches = np.array([np.sum(matches['PWGTP'][:j+1]) for j in range(len(matches))])\n",
    "        act_ch = np.random.randint(0,weighted_matches[-1])  \n",
    "        wh_final.append(i)\n",
    "        bl_final.append(matches.index[list(act_ch <=weighted_matches).index(True)])\n",
    "    wh_analyze = wh_some_hs.loc[wh_final]\n",
    "    bl_analyze = bl_some_hs.loc[bl_final]\n",
    "    wh_median = np.median(wh_analyze['PINCP'])\n",
    "    bl_median = np.median(bl_analyze['PINCP'])\n",
    "    return [wh_median,bl_median]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell makes the list of all state codes. Presumably the skipped values are US territories or similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = [1,2,4,5,6,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24]\n",
    "states.extend(np.arange(25,43))\n",
    "states.extend(np.arange(44,52))\n",
    "states.extend(np.arange(53,57))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this block will write the median white/black salaries to \"states.race.income.dat\". From there we can plot them however we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = []\n",
    "b = []\n",
    "for i in states:\n",
    "    data = racially_biased_salaries(i,14000)\n",
    "    if data == 'Finished':\n",
    "        continue\n",
    "    w1,b1 = data\n",
    "    f=open(\"states.race.income.dat\", \"a+\")\n",
    "    f.write('{0} {1} {2}\\n'.format(i,w1,b1))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
